# Sistema RAG di Business Intelligence ğŸ¢

Una **piattaforma di Business Intelligence aziendale di nuova generazione** che combina l'analisi di dati strutturati con funzionalitÃ  avanzate RAG (Retrieval-Augmented Generation). Costruita con **Clean Architecture**, **Domain-Driven Design**, e **pattern di livello enterprise** per analisi finanziarie scalabili e intelligenza documentale.

## ğŸ¯ FunzionalitÃ  Principali

### ğŸš€ **NOVITÃ€: Architettura Enterprise Avanzata + Performance Optimization (2025)**
- **ğŸ”§ Attivazione Enterprise**: ModalitÃ  enterprise con un clic nella barra laterale Streamlit
- **âš¡ Performance Ultra-Ottimizzate**: Connection pooling, cache distribuita Redis, background jobs Celery
- **ğŸ”„ Horizontal Scaling**: Load balancing Nginx, auto-scaling Docker, alta disponibilitÃ 
- **ğŸ“Š Dashboard Analytics Avanzato**: KPI interattivi, trend analysis, waterfall charts, radar efficienza
- **ğŸ” Anteprima Documenti**: Thumbnails automatici, estrazione contenuti, statistiche documenti
- **âœï¸ Editor Interattivo Metriche**: Editing real-time, validazione automatica, suggerimenti AI
- **ğŸ“ˆ Visualizzazioni Professionali**: Plotly charts, gauge KPI, heatmap rischio
- **ğŸ¯ 68 Metriche Finanziarie**: Ontologia estesa AR/AP, Vendite, Magazzino, HR
- **âœ… Great Expectations**: Validazioni data quality sistematiche su coerenza contabile
- **ğŸ”„ Calcoli Derivati Automatici**: 15+ formule finanziarie con lineage completo  
- **ğŸ” Provenienza Granulare**: Tracking pagina/cella/coordinata per massima tracciabilitÃ 
- **ğŸ“Š Riferimenti Origine**: Tracciamento completo provenienza dati (file.xlsx|sheet:CE|cell:B12)
- **ğŸ¤– Recupero Ibrido**: BM25 + Embeddings + Riclassificazione con cross-encoder
- **ğŸ—„ï¸ Tabella Dimensionale**: Schema a stella con persistenza DuckDB/SQLite
- **âš¡ Orchestrazione Enterprise Avanzata**: Pipeline 6 fasi con quality checks e calculations

### ğŸ“Š Analisi Finanziarie Avanzate
- **Elaborazione CSV Intelligente** con supporto per formati numerici italiani (`1.234,56`)
- **Modellazione Finanziaria Automatizzata** (crescita YoY, rapporti, KPI)
- **Calcoli Derivati Automatici** - 15 formule finanziarie (PFN, ROS, ROIC, Current Ratio, DSO, ecc.)
- **Lineage Tracking Completo** - tracciamento formula + inputs + confidence per ogni calcolo
- **Data Quality Enterprise** - validazioni Great Expectations su coerenza bilancio/PFN
- **Rilevamento Anomalie** con algoritmi statistici e range validation
- **Supporto Multi-Valuta** con tracciamento delle conversioni
- **Dashboard Interattive** con visualizzazioni in tempo reale
- **Analisi Comparativa** tra piÃ¹ periodi ed entitÃ 

### ğŸ§  Intelligenza Documentale Basata su RAG  
- **Supporto Multi-Formato** (PDF, DOCX, TXT, Markdown, Excel)
- **Estrazione Avanzata** - OCR Tesseract, Camelot/Tabula per tabelle PDF, parsing Excel
- **Provenienza Granulare** - tracking preciso pagina/cella (es: "bilancio.xlsx|sheet:CE|cell:B12")
- **Ricerca Semantica** con database vettoriale Qdrant
- **Query Context-Aware** che combinano dati strutturati e non strutturati
- **Estrazione Metadati** con tracciamento completo della provenienza
- **Export PDF Professionale** con stile ZCS Company
- **Chunking Intelligente** con ottimizzazione delle sovrapposizioni

### ğŸ¤– Business Intelligence Guidata dall'AI
- **Report Esecutivi** con insight strategici
- **Analisi Predittive** basate su pattern storici
- **Valutazione del Rischio** con punteggi di confidenza
- **Query in Linguaggio Naturale** in italiano e inglese
- **Raccomandazioni Automatiche** con livelli di prioritÃ 
- **Analisi dei Trend** con significativitÃ  statistica

### âš¡ **NOVITÃ€: Performance Optimization Enterprise (2025)**
- **ğŸ”— Connection Pooling**: Gestione ottimizzata connessioni database con pool configurabili
- **ğŸ—„ï¸ Cache Distribuita Redis**: Caching in-memory ultra-veloce per query e sessioni utente
- **âš™ï¸ Background Job Processing**: Code Celery per elaborazioni pesanti (indicizzazione, analisi)
- **ğŸ”„ Horizontal Scaling**: Load balancer Nginx con auto-scaling e health checks
- **ğŸ“Š Monitoring Avanzato**: Dashboard Flower per monitoraggio real-time task e performance
- **ğŸš€ Auto-Deployment**: Script automatici per setup completo dell'infrastruttura
- **ğŸ“ˆ Performance Analytics**: Metriche dettagliate su hit rate cache, connection pool, response time
- **ğŸ”§ Configurazione Elastica**: Scaling dinamico basato su carico con soglie configurabili

### ğŸ’¼ Architettura Enterprise-Ready
- **Clean Architecture** con separazione dei domini
- **Pattern Repository** con persistenza SQLite/DuckDB
- **Data Quality Service** - Great Expectations per validazioni sistematiche
- **Calculation Engine** - motore calcoli derivati con dependency resolution
- **Granular Provenance Service** - tracciamento provenienza cella-per-cella
- **Advanced Enterprise Orchestrator** - coordinamento pipeline completo
- **Dependency Injection** container
- **Logging Completo** con filtraggio dei dati sensibili
- **Type Safety** con piena conformitÃ  MyPy
- **Gestione Errori** con eccezioni strutturate
- **Degradazione Graduale** per componenti enterprise opzionali

## ğŸ—ï¸ Panoramica dell'Architettura

### Progettazione del Sistema
L'applicazione segue i principi della **Clean Architecture** con una chiara separazione dei livelli:

```mermaid
graph TD
    UI[Streamlit UI] --> APP[Livello Applicazione]
    APP --> DOMAIN[Livello Dominio] 
    APP --> INFRA[Livello Infrastruttura]
    
    subgraph "Livello Dominio"
        ENT[EntitÃ ]
        VO[Oggetti Valore]
        EXC[Eccezioni]
    end
    
    subgraph "Livello Applicazione"  
        INT[Interfacce]
        UC[Casi d'Uso]
        DTO[DTOs]
    end
    
    subgraph "Livello Infrastruttura"
        REPO[Repository]
        EXT[Servizi Esterni]
        PERS[Persistenza]
    end
```

### Stack Tecnologico Enterprise

| Livello | Componente | Tecnologia | Scopo |
|---------|------------|------------|--------|
| **Presentazione** | Framework UI | Streamlit 1.29+ | Interfaccia web con modalitÃ  Enterprise |
| **Applicazione** | Logica di Business | Python 3.10+ | Casi d'uso e interfacce |
| | **Orchestratore Enterprise** | **Pipeline Personalizzata** | **Flusso di lavoro a 6 fasi** |
| | **Router Documenti** | **Classificazione Contenuti** | **Routing Strutturato/Non Strutturato** |
| | **Recupero Ibrido** | **BM25 + Embeddings** | **Ricerca avanzata con riclassificazione** |
| **Performance** | **Connection Pooling** | **Custom Pool Manager** | **Gestione ottimizzata connessioni DB** |
| | **Cache Distribuita** | **Redis 7+** | **Caching in-memory sessioni/query** |
| | **Background Jobs** | **Celery 5.5+** | **Task asincroni e scheduled** |
| | **Load Balancing** | **Nginx** | **Distribuzione carico multi-istanza** |
| | **Task Monitoring** | **Flower 2.0+** | **Dashboard monitoraggio real-time** |
| **Dominio** | Modelli Core | Pydantic 2.0+ | EntitÃ  e oggetti valore |
| | **Riferimenti Origine** | **Tracciamento Provenienza** | **Lineage completo dei dati** |
| | **Controlli Finanziari** | **Regole di Validazione** | **Verifiche coerenza bilancio** |
| **Infrastruttura** | Database Vettoriale | Qdrant 1.7+ | Ricerca semantica |
| | **Tabella Fatti** | **DuckDB/SQLite** | **Data warehouse dimensionale** |
| | Servizio LLM | OpenAI GPT-4 | Ragionamento AI |
| | **Mappatura Ontologia** | **YAML + RapidFuzz** | **31 metriche, oltre 219 sinonimi** |
| | **Normalizzazione Dati** | **Supporto Multi-locale** | **Formati e periodi italiani** |
| | Elaborazione Dati | Pandas 2.1+ | Analisi CSV |
| | Visualizzazione | Plotly 5.18+ | Grafici interattivi |
| **ML/AI** | **Embeddings** | **SentenceTransformers** | **Modello All-MiniLM-L6-v2** |
| | **Reranker** | **CrossEncoder** | **MS-MARCO-MiniLM-L-2-v2** |
| | **Ricerca** | **BM25Okapi** | **Recupero basato su parole chiave** |
| **DevOps** | Package Manager | uv | Dipendenze veloci |
| | Linting | Ruff + Black | QualitÃ  del codice |
| | Controllo Tipi | MyPy | Sicurezza dei tipi |
| | Testing | Pytest | Garanzia qualitÃ  |
| | **Containerization** | **Docker + Compose** | **Deployment scalabile** |

## Prerequisiti

- **Python 3.10+**
- **Chiave API OpenAI** (richiesta per LLM ed embeddings)
- **Docker + Docker Compose** (richiesto per Redis, Qdrant e scaling)
- **8GB+ RAM** (raccomandato per operazioni vettoriali e cache Redis)
- **Tesseract OCR** (richiesto per estrazione testo PDF e funzionalitÃ  OCR)

### ğŸš€ **NUOVO: Performance Optimization Requirements**
- **Redis 7+** (per cache distribuita e sessioni)
- **Nginx** (per load balancing e reverse proxy)
- **Celery + Flower** (per background jobs e monitoring)
- **16GB+ RAM** (raccomandato per deployment enterprise con scaling)
- **Multi-core CPU** (per performance ottimali con connection pooling)

## Installazione

### Opzione 1: Avvio Rapido (Raccomandato)

```bash
# 1. Clona il repository
git clone <repository-url>
cd RAG

# 2. Configura l'ambiente
cp .env.example .env
# Modifica .env e aggiungi la tua OPENAI_API_KEY

# 3. Avvio automatico (installa uv se mancante)
start.bat      # Windows  
./start.sh     # Linux/Mac

# 4. Apri il browser: http://localhost:8501
```

### Opzione 2: Configurazione Manuale con uv

```bash
# Installa uv (se non presente)
curl -LsSf https://astral.sh/uv/install.sh | sh  # Linux/Mac
powershell -c "irm https://astral.sh/uv/install.ps1 | iex"  # Windows

# Configura l'ambiente
uv venv                              # Crea ambiente virtuale
source .venv/bin/activate           # Linux/Mac
.venv\Scripts\activate              # Windows

# Installa le dipendenze (10-100x piÃ¹ veloce di pip)
uv pip install -r requirements.txt

# Avvia Qdrant
docker run -p 6333:6333 -p 6334:6334 qdrant/qdrant

# Avvia l'applicazione
streamlit run app.py
```

### Opzione 3: Deployment Docker

```bash
# Configurazione completa con un comando
cp .env.example .env  # Aggiungi OPENAI_API_KEY
docker-compose up -d

# Accedi all'app: http://localhost:8501
# UI Qdrant: http://localhost:6333/dashboard
```

### ğŸš€ **NUOVO: Opzione 4: Performance Optimization Setup**

```bash
# Setup automatico completo performance optimization
.\scripts\deploy_performance.bat     # Windows
./scripts/deploy_performance.sh      # Linux/Mac

# Setup alternativo con Python script
python setup_performance.py

# Verifica deployment
python test_performance_final.py

# Servizi attivati:
# - Redis: localhost:6379 (cache distribuita)
# - Qdrant: localhost:6333 (database vettoriale)
# - Celery Worker: background jobs
# - Flower: localhost:5555 (monitoring)
```

### ğŸ”§ **Performance Optimization Manuale**

```bash
# 1. Setup Redis + Qdrant
docker run -d --name rag_redis -p 6379:6379 redis:7-alpine
docker run -d --name rag_qdrant -p 6333:6333 qdrant/qdrant

# 2. Installa dependencies performance
pip install redis celery flower

# 3. Avvia Celery worker
celery -A src.infrastructure.performance.celery_tasks worker --loglevel=info

# 4. Avvia Flower monitoring
flower -A src.infrastructure.performance.celery_tasks --port=5555

# 5. Deployment scaling (produzione)
docker-compose -f docker-compose.scaling.yml up -d --scale app=3
```

### Installazione Dipendenze OCR

L'applicazione richiede **Tesseract OCR** per l'estrazione di testo dai PDF e la funzionalitÃ  OCR.

#### Installazione Windows

**Opzione 1: Utilizzo di Windows Package Manager (Raccomandato)**
```bash
# Installa usando winget (Windows 10+)
winget install --id UB-Mannheim.TesseractOCR

# Verifica l'installazione
tesseract --version
```

**Opzione 2: Installazione Manuale**
1. Scarica l'installer piÃ¹ recente di Tesseract da [UB Mannheim](https://github.com/UB-Mannheim/tesseract/releases)
2. Esegui l'installer (`tesseract-ocr-w64-setup-5.x.x.exe`)
3. Assicurati di selezionare "Aggiungi al PATH" durante l'installazione
4. Riavvia il terminale/prompt dei comandi
5. Verifica: `tesseract --version`

**Se Tesseract non Ã¨ nel PATH:**
```bash
# Aggiungi alla sessione corrente (temporaneo)
set PATH=C:\Program Files\Tesseract-OCR;%PATH%

# Oppure aggiungi permanentemente C:\Program Files\Tesseract-OCR al PATH di sistema
```

#### Installazione Linux
```bash
# Ubuntu/Debian
sudo apt update && sudo apt install tesseract-ocr

# CentOS/RHEL/Fedora
sudo yum install tesseract  # oppure sudo dnf install tesseract

# Verifica
tesseract --version
```

#### Installazione macOS
```bash
# Usando Homebrew
brew install tesseract

# Verifica
tesseract --version
```

**Nota:** Se Tesseract non Ã¨ installato, l'applicazione mostrerÃ  un avviso e la funzionalitÃ  OCR sarÃ  disabilitata, ma le altre funzionalitÃ  continueranno a funzionare.

## Configurazione

### Variabili d'Ambiente (.env)

```env
# OpenAI (Obbligatorio)
OPENAI_API_KEY=sk-...la-tua-chiave-qui...

# Database Vettoriale Qdrant
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=business_documents

# Configurazione AI
LLM_MODEL=gpt-4-turbo-preview
EMBEDDING_MODEL=text-embedding-3-small
TEMPERATURE=0.1
MAX_TOKENS=2000

# Elaborazione Documenti
CHUNK_SIZE=512
CHUNK_OVERLAP=50

# Performance RAG
RAG_RESPONSE_MODE=compact
RAG_SIMILARITY_TOP_K=3
RAG_ENABLE_CACHING=True

# Performance Optimization (NUOVO)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_DB=0
CELERY_BROKER_URL=redis://localhost:6379/0
CELERY_RESULT_BACKEND=redis://localhost:6379/0

# Connection Pooling
QDRANT_POOL_MIN_SIZE=2
QDRANT_POOL_MAX_SIZE=10
DUCKDB_POOL_MIN_SIZE=1
DUCKDB_POOL_MAX_SIZE=5

# FunzionalitÃ  Enterprise
HF_HUB_DISABLE_SYMLINKS_WARNING=1

# Applicazione
DEBUG_MODE=false
APP_NAME=Sistema RAG di Business Intelligence
```

## ğŸ“ Struttura del Progetto Enterprise

```
src/
â”œâ”€â”€ domain/                    # Logica di business principale (entitÃ , oggetti valore)
â”‚   â”œâ”€â”€ entities/             # EntitÃ  di business (FinancialData, Document, AnalysisResult)
â”‚   â”œâ”€â”€ value_objects/        # NUOVO: Riferimenti origine, controlli, validazione
â”‚   â”‚   â”œâ”€â”€ source_reference.py    # Tracciamento completo provenienza dati
â”‚   â”‚   â””â”€â”€ guardrails.py          # Regole di validazione finanziaria
â”‚   â”œâ”€â”€ services/             # NUOVO: Servizi enterprise core
â”‚   â”‚   â”œâ”€â”€ data_quality_service.py      # Great Expectations per data quality
â”‚   â”‚   â”œâ”€â”€ calculation_engine.py        # Calcoli derivati con lineage  
â”‚   â”‚   â””â”€â”€ granular_provenance_service.py  # Provenienza granulare
â”‚   â””â”€â”€ exceptions/           # Eccezioni specifiche del dominio
â”œâ”€â”€ application/              # Casi d'uso e interfacce  
â”‚   â”œâ”€â”€ interfaces/           # Contratti per dipendenze esterne
â”‚   â””â”€â”€ services/             # NUOVO: Servizi applicativi enterprise
â”‚       â”œâ”€â”€ enterprise_orchestrator.py       # Coordinatore principale del flusso
â”‚       â”œâ”€â”€ advanced_enterprise_orchestrator.py  # NUOVO: Orchestratore avanzato integrato
â”‚       â”œâ”€â”€ document_router.py               # Classificazione documenti
â”‚       â”œâ”€â”€ hybrid_retrieval.py              # Ricerca BM25 + Embeddings
â”‚       â”œâ”€â”€ ontology_mapper.py               # Mappatura sinonimi metriche (68 metriche)
â”‚       â”œâ”€â”€ data_normalizer.py               # Normalizzazione multi-locale
â”‚       â”œâ”€â”€ document_preview.py              # NUOVO: Anteprima documenti con thumbnails
â”‚       â”œâ”€â”€ interactive_editor.py            # NUOVO: Editor interattivo metriche
â”‚       â””â”€â”€ analytics_dashboard.py           # NUOVO: Dashboard analytics avanzato
â”œâ”€â”€ infrastructure/           # Aspetti esterni (database, API)
â”‚   â”œâ”€â”€ repositories/         # Implementazioni persistenza dati
â”‚   â”‚   â””â”€â”€ fact_table_repository.py   # Data warehouse dimensionale
â”‚   â””â”€â”€ performance/          # NUOVO: Moduli ottimizzazione performance
â”‚       â”œâ”€â”€ connection_pool.py         # Connection pooling per DB
â”‚       â”œâ”€â”€ redis_cache.py             # Cache distribuita Redis
â”‚       â”œâ”€â”€ celery_tasks.py            # Background jobs Celery
â”‚       â””â”€â”€ load_balancer.py           # Load balancing e scaling
â”œâ”€â”€ core/                     # Aspetti trasversali
â”‚   â”œâ”€â”€ config.py            # Gestione configurazione
â”‚   â”œâ”€â”€ logging_config.py    # Logging strutturato
â”‚   â””â”€â”€ dependency_injection.py # Container DI
â”œâ”€â”€ presentation/             # Livello UI (Streamlit)
â”‚   â””â”€â”€ streamlit/
â”‚       â””â”€â”€ pdf_exporter.py   # NUOVO: Export PDF professionale (stile ZCS)
â”œâ”€â”€ pages/                    # NUOVO: Pagine UI/UX avanzate
â”‚   â”œâ”€â”€ 1_ğŸ“Š_Analytics_Dashboard.py    # Dashboard KPI interattivo
â”‚   â”œâ”€â”€ 2_ğŸ”_Document_Preview.py       # Anteprima documenti con thumbnails
â”‚   â””â”€â”€ 3_âœï¸_Interactive_Editor.py      # Editor metriche real-time
â””â”€â”€ services/                 # Servizi legacy (in migrazione)
    â”œâ”€â”€ rag_engine.py        # Potenziato con orchestratore enterprise
    â””â”€â”€ query_cache.py       # Ottimizzazione performance

config/
â””â”€â”€ ontology/                 # NUOVO: Ontologia metriche finanziarie
    â””â”€â”€ financial_metrics.yaml     # 31 metriche, oltre 219 sinonimi

scripts/                      # NUOVO: Script deployment e automation
â”œâ”€â”€ deploy_performance.bat           # Script Windows performance setup
â””â”€â”€ deploy_performance.sh            # Script Linux/Mac performance setup

docker-compose.scaling.yml     # NUOVO: Configurazione Docker scaling
nginx/                        # NUOVO: Configurazione Nginx load balancer
â””â”€â”€ nginx.conf               # Reverse proxy e load balancing

docs/                         # NUOVO: Documentazione avanzata
â””â”€â”€ PERFORMANCE_OPTIMIZATION.md  # Guida completa performance

tests/
â”œâ”€â”€ unit/                     # Test unitari per logica dominio
â”œâ”€â”€ integration/              # Test integrazione per repository
â”œâ”€â”€ e2e/                     # Test end-to-end flussi lavoro
â””â”€â”€ test_performance.py      # NUOVO: Test suite performance optimization

# File setup performance
setup_performance.py         # NUOVO: Setup automatico performance optimization
test_performance_final.py    # NUOVO: Test finale verifica deployment
requirements.performance.txt # NUOVO: Dependencies performance optimization
```

## ğŸš€ Guida all'Uso

### ğŸš€ **NUOVO: Utilizzo ModalitÃ  Enterprise**

**Attiva le FunzionalitÃ  Enterprise:**
1. **Attiva la ModalitÃ  Enterprise** nella barra laterale di Streamlit (ğŸš€ ModalitÃ  Enterprise)
2. **Carica Documenti Finanziari** (PDF, Excel, Word)
3. **Poni Domande** - La pipeline Enterprise automaticamente:
   - Instradata i documenti (strutturati/non strutturati/ibridi)
   - Esegue recupero ibrido (BM25 + embeddings + riclassificazione)
   - Estrae e normalizza le metriche finanziarie
   - Mappa all'ontologia canonica (Italiano â†” Inglese)
   - Valida la coerenza del bilancio
   - Archivia con piena provenienza nella tabella dimensionale

**I Risultati delle Query Enterprise Includono:**
- **ğŸ“Š Metriche Rilevate**: Valori normalizzati con punteggi di confidenza
- **âœ… Risultati di Validazione**: Controlli di coerenza (bilancio, PFN)
- **âš¡ Statistiche di Elaborazione**: Tempo, confidenza, record salvati
- **ğŸ” Riferimenti di Origine**: Provenienza completa dei dati
- **âš ï¸ Avvisi di Validazione**: Incongruenze contabili segnalate

### ğŸš€ **NUOVO: FunzionalitÃ  UI/UX Avanzate**

#### ğŸ“Š Dashboard Analytics Avanzato (`1_ğŸ“Š_Analytics_Dashboard.py`)
- **Gauge KPI Interattivi**: Visualizzazione metriche con soglie e colori dinamici
- **Waterfall Charts**: Analisi breakdown finanziario (Ricavi â†’ EBITDA â†’ Utile Netto)
- **Trend Analysis**: Grafici temporali con analisi crescita YoY
- **Health Score**: Punteggio di salute aziendale con algoritmi di scoring
- **Radar Efficienza**: Visualizzazione multi-dimensionale delle performance
- **Risk Assessment**: Analisi del rischio con matrice di valutazione

#### ğŸ” Anteprima Documenti (`2_ğŸ”_Document_Preview.py`)
- **Supporto Multi-Formato**: PDF, Excel, CSV, Immagini, Text, JSON, Markdown
- **Thumbnails Automatici**: Generazione preview pagine PDF e documenti
- **Estrazione Contenuti**: Analisi automatica e preview del testo
- **Statistiche Documenti**: Metadati dettagliati e analisi qualitÃ  dati
- **Rilevamento Metriche**: Identificazione automatica valori finanziari
- **Sistema Caching**: Ottimizzazione performance per documenti ricorrenti
- **Export Funzionale**: Download dati preview in formato JSON

#### âœï¸ Editor Interattivo Metriche (`3_âœï¸_Interactive_Editor.py`)
- **Editing Real-Time**: Modifica valori con validazione immediata
- **Gestione Sessioni**: Controllo stato editing multi-utente
- **Suggerimenti AI**: Raccomandazioni automatiche per correzioni
- **Cronologia Modifiche**: Tracking completo operazioni con undo/redo
- **Validazione Avanzata**: Controlli dominio (AR/AP, Sales, HR, Inventory)
- **Integrazione Ontologia**: Mappatura automatica sinonimi 68 metriche
- **Import/Export Bulk**: FunzionalitÃ  caricamento/scaricamento dati massivo

### 1. ğŸ“Š Analisi Dati Finanziari

**Elaborazione CSV di Livello Enterprise:**
1. **Upload Intelligente**: Rileva automaticamente i formati italiani (`1.234,56`, formati data)
2. **Modellazione Finanziaria**: Calcolo automatico di KPI e analisi dei trend
3. **Analisi Avanzate**:
   - Crescita YoY con significativitÃ  statistica
   - Rapporti finanziari e analisi dei margini
   - Rilevamento anomalie con punteggi di confidenza
   - Analisi comparative multi-periodo
4. **Visualizzazioni Interattive**: Dashboard Plotly con capacitÃ  di drill-down

### 2. ğŸ” Intelligenza Documentale RAG

**Elaborazione Semantica dei Documenti:**
1. **Ingestione Multi-Formato**: PDF, DOCX, TXT, Markdown con estrazione metadati
2. **Indicizzazione Intelligente**: Chunking context-aware con archiviazione vettoriale Qdrant
3. **Query in Linguaggio Naturale**: Poni domande complesse in italiano o inglese
4. **Integrazione del Contesto**: Combina insights dei dati finanziari con il contenuto dei documenti
5. **Export PDF Professionale** - Esporta sessioni Q&A con stile ZCS Company

### 3. ğŸ¤– Business Intelligence Basata su AI

**Supporto Decisionale Strategico:**
- **Dashboard Esecutive**: Report pronti per il C-suite con insight chiave
- **Analisi Predittive**: Previsioni sui trend con intervalli di confidenza  
- **Valutazione del Rischio**: Scoring automatico del rischio con strategie di mitigazione
- **Report di ConformitÃ **: Documentazione pronta per audit con tracciamento provenienza
- **Supporto Multi-Lingua**: Elaborazione query in italiano e inglese

### âš¡ **NUOVO: 4. Performance Monitoring e Optimization**

**Dashboard Performance Enterprise:**
- **ğŸ”§ Connection Pool Status**: Monitoraggio real-time pool connessioni DB
- **ğŸ“Š Redis Cache Analytics**: Hit rate, memory usage, key statistics
- **âš™ï¸ Celery Task Queue**: Background jobs status, workers health, task throughput
- **ğŸŒ Load Balancer Metrics**: Distribuzione carico, health checks, response times
- **ğŸ“ˆ Performance Dashboard**: Grafici interattivi su latenza, throughput, errori

**Accesso Monitoring:**
```bash
# Flower Dashboard (Celery monitoring)
http://localhost:5555

# Redis CLI per cache inspection
docker exec -it rag_redis redis-cli

# Qdrant dashboard
http://localhost:6333/dashboard

# Nginx status (se configurato)
http://localhost/nginx-status

# Application performance metrics
http://localhost:8502 â†’ Sidebar "Performance Stats"
```

## ğŸ› ï¸ Sviluppo

### Garanzia della QualitÃ 

```bash
# QualitÃ  del Codice
ruff check .                       # Linting veloce con oltre 800 regole
black .                           # Formattazione coerente del codice  
mypy src/                         # Controllo dei tipi
bandit src/                       # Scansione sicurezza

# Suite di Test  
pytest                            # Esegui tutti i test (obiettivo copertura 80%)
pytest -m unit                   # Solo test unitari
pytest -m integration            # Test di integrazione  
pytest -v --tb=short            # Output dettagliato

# Test delle Prestazioni
pytest -m slow                   # Benchmark delle prestazioni
pytest --cov=src --cov-report=html  # Report di copertura

# Test UI/UX Integration
python test_ui_integration.py    # Test completo funzionalitÃ  UI/UX avanzate

# Performance Optimization Testing (NUOVO)
python test_performance_final.py # Test completo performance optimization
pytest tests/test_performance.py # Test suite performance components
```

### Gestione Dipendenze

```bash
# Gestione dipendenze veloce con uv (10-100x piÃ¹ veloce di pip)
uv add nome-pacchetto              # Aggiungi dipendenza di produzione
uv add --dev nome-pacchetto        # Aggiungi dipendenza di sviluppo
uv remove nome-pacchetto           # Rimuovi dipendenza
uv pip compile requirements.txt   # Aggiorna file di lock
uv sync                           # Sincronizza ambiente
```

### Architecture Validation

```bash
# Domain Model Validation
python -m src.domain.entities.financial_data  # Test entity integrity
python -m src.domain.value_objects.money     # Test value objects

# Repository Testing  
python -m src.infrastructure.repositories    # Test data persistence

# Dependency Injection Validation
python -m src.core.dependency_injection      # Test DI container
```

## Risoluzione Problemi

### Problemi Comuni

#### Errori API OpenAI
```bash
# Chiave API non valida
export OPENAI_API_KEY=sk-la-tua-chiave-qui
# Oppure modifica il file .env

# Limite di velocitÃ  superato  
# Soluzione: Riduci la frequenza delle richieste o aggiorna il piano
```

#### Problemi di Connessione Qdrant
```bash
# Controlla lo stato di Qdrant
curl http://localhost:6333/health

# Riavvia Qdrant
docker restart qdrant
```

#### Problemi di Memoria
```bash
# Riduci la dimensione del chunk
CHUNK_SIZE=256  # Default: 512

# Aumenta la memoria Docker
docker-compose up --memory=4g
```

#### ğŸš€ **NUOVO: Problemi Performance Optimization**

**Redis Connection Issues:**
```bash
# Test connessione Redis
docker exec -it rag_redis redis-cli ping

# Restart Redis container
docker restart rag_redis

# Check Redis memory usage
docker exec rag_redis redis-cli info memory
```

**Celery Worker Issues:**
```bash
# Check workers status
celery -A src.infrastructure.performance.celery_tasks status

# Restart workers
pkill -f celery
celery -A src.infrastructure.performance.celery_tasks worker --loglevel=info

# Monitor with Flower
flower -A src.infrastructure.performance.celery_tasks --port=5555
```

**Connection Pool Issues:**
```bash
# Check pool statistics
python -c "from src.infrastructure.performance.connection_pool import get_qdrant_pool; print(get_qdrant_pool().get_stats())"

# Reset pools
docker restart rag_redis rag_qdrant
python setup_performance.py
```

**Load Balancer Issues:**
```bash
# Test Nginx configuration
nginx -t

# Restart load balancer
docker-compose -f docker-compose.scaling.yml restart nginx

# Check service health
curl http://localhost/health
```

## Contribuire

1. **Fork** del repository
2. **Crea branch feature**: `git checkout -b feature/funzionalita-incredibile`
3. **Commit delle modifiche**: `git commit -m 'Aggiungi funzionalitÃ  incredibile'`
4. **Push al branch**: `git push origin feature/funzionalita-incredibile`
5. **Apri Pull Request**

## Licenza

Questo progetto Ã¨ rilasciato sotto la **Licenza MIT** - vedi [LICENSE](LICENSE) per i dettagli.

## Supporto

- **Problemi**: GitHub Issues per segnalazioni di bug
- **Discussioni**: GitHub Discussions per domande e risposte
- **Documentazione**: Wiki completa su GitHub

---

**Pronto a trasformare i tuoi dati in business intelligence enterprise-grade?**

ğŸš€ **Quick Start**: `start.bat` (standard)
âš¡ **Performance**: `.\scripts\deploy_performance.bat` (ottimizzato)
ğŸŒ **Enterprise**: `docker-compose -f docker-compose.scaling.yml up -d` (scaling)

**Il futuro dell'AI aziendale Ã¨ qui - inizia ora!**